{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import app\n",
    "from nasbench import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = 'input'\n",
    "OUTPUT = 'output'\n",
    "CONV1X1 = 'conv1x1-bn-relu'\n",
    "CONV3X3 = 'conv3x3-bn-relu'\n",
    "MAXPOOL3X3 = 'maxpool3x3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from file... This may take a few minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5083488/5083488 [01:59<00:00, 42649.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset in 119 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data from file (this will take some time)\n",
    "nasbench = api.NASBench('./dataset/nasbench_full.tfrecord')\n",
    "\n",
    "# Create an Inception-like module (5x5 convolution replaced with two 3x3\n",
    "# convolutions).\n",
    "model_spec = api.ModelSpec(\n",
    "    # Adjacency matrix of the module\n",
    "    matrix=[[0, 1, 1, 1, 0, 1, 0],    # input layer\n",
    "            [0, 0, 0, 0, 0, 0, 1],    # 1x1 conv\n",
    "            [0, 0, 0, 0, 0, 0, 1],    # 3x3 conv\n",
    "            [0, 0, 0, 0, 1, 0, 0],    # 5x5 conv (replaced by two 3x3's)\n",
    "            [0, 0, 0, 0, 0, 0, 1],    # 5x5 conv (replaced by two 3x3's)\n",
    "            [0, 0, 0, 0, 0, 0, 1],    # 3x3 max-pool\n",
    "            [0, 0, 0, 0, 0, 0, 0]],   # output layer\n",
    "    # Operations at the vertices of the module, matches order of matrix\n",
    "    ops=[INPUT, CONV1X1, CONV3X3, CONV3X3, CONV3X3, MAXPOOL3X3, OUTPUT])\n",
    "\n",
    "# Query this model from dataset, returns a dictionary containing the metrics\n",
    "# associated with this model.\n",
    "data = nasbench.query(model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'module_adjacency': array([[0, 1, 1, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0]], dtype=int8),\n",
       " 'module_operations': ['input',\n",
       "  'conv3x3-bn-relu',\n",
       "  'conv1x1-bn-relu',\n",
       "  'maxpool3x3',\n",
       "  'conv3x3-bn-relu',\n",
       "  'conv3x3-bn-relu',\n",
       "  'output'],\n",
       " 'trainable_parameters': 2694282,\n",
       " 'training_time': 1157.675048828125,\n",
       " 'train_accuracy': 1.0,\n",
       " 'validation_accuracy': 0.9378004670143127,\n",
       " 'test_accuracy': 0.932692289352417}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no data files provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/rockerbox/Desktop/nasbench/test.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/rockerbox/Desktop/nasbench/test.ipynb#ch0000004?line=0'>1</a>\u001b[0m nasbench\u001b[39m.\u001b[39;49mevaluate(model_spec, \u001b[39m'\u001b[39;49m\u001b[39m./test_output\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/nasbench/nasbench/api.py:328\u001b[0m, in \u001b[0;36mNASBench.evaluate\u001b[0;34m(self, model_spec, model_dir)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39m\"\"\"Trains and evaluates a model spec from scratch (does not query dataset).\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \n\u001b[1;32m    310\u001b[0m \u001b[39mThis function runs the same procedure that was used to generate each\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m  returned by query().\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[39m# Metadata contains additional metrics that aren't reported normally.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[39m# However, these are stored in the JSON file at the model_dir.\u001b[39;00m\n\u001b[0;32m--> 328\u001b[0m metadata \u001b[39m=\u001b[39m evaluate\u001b[39m.\u001b[39;49mtrain_and_evaluate(model_spec, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig, model_dir)\n\u001b[1;32m    329\u001b[0m metadata_file \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(model_dir, \u001b[39m'\u001b[39m\u001b[39mmetadata.json\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    330\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mOpen(metadata_file, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Desktop/nasbench/nasbench/lib/evaluate.py:56\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(spec, config, model_dir)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_and_evaluate\u001b[39m(spec, config, model_dir):\n\u001b[1;32m     43\u001b[0m   \u001b[39m\"\"\"Train and evaluate the proposed model.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[39m  This method trains and evaluates the model for the creation of the benchmark\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m    dict containing the evaluation metadata.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m   \u001b[39mreturn\u001b[39;00m _train_and_evaluate_impl(spec, config, model_dir)\n",
      "File \u001b[0;32m~/Desktop/nasbench/nasbench/lib/evaluate.py:85\u001b[0m, in \u001b[0;36m_train_and_evaluate_impl\u001b[0;34m(spec, config, model_dir)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_and_evaluate_impl\u001b[39m(spec, config, model_dir):\n\u001b[1;32m     84\u001b[0m   \u001b[39m\"\"\"Train and evaluate implementation, see train_and_evaluate docstring.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m   evaluator \u001b[39m=\u001b[39m _TrainAndEvaluator(spec, config, model_dir)\n\u001b[1;32m     86\u001b[0m   \u001b[39mreturn\u001b[39;00m evaluator\u001b[39m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/Desktop/nasbench/nasbench/lib/evaluate.py:94\u001b[0m, in \u001b[0;36m_TrainAndEvaluator.__init__\u001b[0;34m(self, spec, config, model_dir)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, spec, config, model_dir):\n\u001b[1;32m     93\u001b[0m   \u001b[39m\"\"\"Initialize evaluator. See train_and_evaluate docstring.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_train \u001b[39m=\u001b[39m cifar\u001b[39m.\u001b[39;49mCIFARInput(\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, config)\n\u001b[1;32m     95\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_train_eval \u001b[39m=\u001b[39m cifar\u001b[39m.\u001b[39mCIFARInput(\u001b[39m'\u001b[39m\u001b[39mtrain_eval\u001b[39m\u001b[39m'\u001b[39m, config)\n\u001b[1;32m     96\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_valid \u001b[39m=\u001b[39m cifar\u001b[39m.\u001b[39mCIFARInput(\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m, config)\n",
      "File \u001b[0;32m~/Desktop/nasbench/nasbench/lib/cifar.py:66\u001b[0m, in \u001b[0;36mCIFARInput.__init__\u001b[0;34m(self, mode, config)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39minvalid mode\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_files:\n\u001b[0;32m---> 66\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mno data files provided\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: no data files provided"
     ]
    }
   ],
   "source": [
    "nasbench.evaluate(model_spec, './test_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nas_with_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6fe5d1d15b756004e991b92666273d0106f4e13b14ed97ed490426778dc23cfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
